{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for peak signal-to-noise ratio (PSNR)\n",
    "import cv2\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "\n",
    "def psnr(target, ref):\n",
    "    # assume RGB image\n",
    "    target_data = numpy.array(target, dtype=float)\n",
    "    ref_data = numpy.array(ref, dtype=float)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')   #flatten in row major\n",
    "\n",
    "    rmse = math.sqrt(numpy.mean(diff ** 2.))\n",
    "\n",
    "    return 20 * math.log10(255.) - 10 * math.log10(rmse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package for data processig\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "HR_PATH = \"HR/\"\n",
    "LR_PATH = \"LR/\"\n",
    "Random_Crop = 30    #every img will be cropped into 30 sub imgs\n",
    "Patch_size = 32     #sub imgs size\n",
    "label_size = 20     #after three filters, the output of img will be smaller than original\n",
    "conv_side = 6       #32-2*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "def prepare_data(HR_path, LR_path):\n",
    "    names_HR = os.listdir(HR_path)\n",
    "    names_HR = sorted(names_HR)\n",
    "    \n",
    "    names_LR = os.listdir(LR_path)\n",
    "    names_LR = sorted(names_LR)  \n",
    "    \n",
    "    nums = names_HR.__len__()\n",
    "    \n",
    "    \n",
    "    data = numpy.zeros((nums * Random_Crop, 1, Patch_size, Patch_size), dtype=numpy.double)\n",
    "    label = numpy.zeros((nums * Random_Crop, 1, label_size, label_size), dtype=numpy.double)\n",
    "\n",
    "    for i in range(nums):\n",
    "        name_HR = HR_path + names_HR[i]\n",
    "        name_LR = LR_path + names_LR[i]\n",
    "        hr_img = cv2.imread(name_HR)\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "\n",
    "        # two resize operation to produce training data and labels\n",
    "        lr_img = cv2.imread(name_LR)\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        lr_img = lr_img[:, :, 0]\n",
    "        \n",
    "\n",
    "        # produce Random_Crop random coordinate to crop training img\n",
    "        Points_x = numpy.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)\n",
    "        Points_y = numpy.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)\n",
    "\n",
    "        for j in range(Random_Crop):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "\n",
    "            lr_patch = lr_patch.astype(float) / 255.\n",
    "            hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "            data[i * Random_Crop + j, 0, :, :] = lr_patch\n",
    "            label[i * Random_Crop + j, 0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "            # cv2.imshow(\"lr\", lr_patch)\n",
    "            # cv2.imshow(\"hr\", hr_patch)\n",
    "            # cv2.waitKey(0)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store data and label\n",
    "def write_hdf5(data, labels, output_filename):\n",
    "    \"\"\"\n",
    "    This function is used to save image data and its label(s) to hdf5 file.\n",
    "    output_file.h5,contain data and label\n",
    "    \"\"\"\n",
    "\n",
    "    x = data.astype(numpy.float32)\n",
    "    y = labels.astype(numpy.float32)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and label\n",
    "def read_training_data(file):\n",
    "    with h5py.File(file, 'r') as hf:\n",
    "        data = numpy.array(hf.get('data'))\n",
    "        label = numpy.array(hf.get('label'))\n",
    "        train_data = numpy.transpose(data, (0, 2, 3, 1))\n",
    "        train_label = numpy.transpose(label, (0, 2, 3, 1))\n",
    "        return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the img data and model label\n",
    "\n",
    "\n",
    "#data, label = prepare_data(HR_path=HR_path, LR_path=LR_path)\n",
    "#write_hdf5(data, label, \"train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SRCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package for model train\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, BatchNormalization\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "#import prepare_data as pd\n",
    "import numpy\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    # lrelu = LeakyReLU(alpha=0.1)\n",
    "    SRCNN = Sequential()\n",
    "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
    "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
    "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
    "                     activation='relu', border_mode='same', bias=True))\n",
    "    # SRCNN.add(BatchNormalization())\n",
    "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
    "                     activation='linear', border_mode='valid', bias=True))\n",
    "    adam = Adam(lr=0.0003)\n",
    "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model():\n",
    "    # lrelu = LeakyReLU(alpha=0.1)\n",
    "    SRCNN = Sequential()\n",
    "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
    "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
    "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
    "                     activation='relu', border_mode='same', bias=True))\n",
    "    # SRCNN.add(BatchNormalization())\n",
    "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
    "                     activation='linear', border_mode='valid', bias=True))\n",
    "    adam = Adam(lr=0.0003)\n",
    "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    srcnn_model = model()\n",
    "    print(srcnn_model.summary())\n",
    "    data, label = read_training_data(\"./crop_train.h5\")\n",
    "    #val_data, val_label = read_training_data(\"./test.h5\")\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"SRCNN_check.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=False, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "                                                #validation_data=(val_data, val_label),\n",
    "    srcnn_model.fit(data, label, batch_size=128, callbacks=callbacks_list, \n",
    "                    shuffle=True, nb_epoch=200, verbose=0)\n",
    "    srcnn_model.save_weights('srcnn.h5')\n",
    "    return(srcnn_model)\n",
    "    # srcnn_model.load_weights(\"m_model_adam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main prediction function最后要用的\n",
    "\n",
    "def predict_score(LR_PATH, HR_PATH):\n",
    "    \n",
    "    # load the srcnn model with weights\n",
    "    srcnn_model = predict_model()\n",
    "    srcnn_model.load_weights('srcnn.h5')\n",
    "    \n",
    "    # load the degraded and reference images\n",
    "    #_, hrfile = os.path.split(HR_PATH)\n",
    "    #_, lrfile = os.path.split(LR_PATH)\n",
    "    #degraded = cv2.imread(image_path)\n",
    "    #ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # preprocess the image with modcrop\n",
    "    hr_img = cv2.imread(HR_PATH)\n",
    "    shape = hr_img.shape\n",
    "\n",
    "    img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # two resize operation to produce training data and labels\n",
    "    lr_img = cv2.imread(LR_PATH)\n",
    "    lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "    lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2YCrCb)\n",
    "    lr_img = lr_img[:, :, 0]\n",
    "    \n",
    "    img[:, :, 0] = lr_img\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    Y = numpy.zeros((1, shape[0], shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = lr_img.astype(float) / 255.\n",
    "    \n",
    "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0\n",
    "    pre = pre.astype(numpy.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)    \n",
    "    score = psnr(hr_img,img)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main prediction function最后要用的\n",
    "\n",
    "def predict(LR_PATH, HR_PATH):\n",
    "    \n",
    "    # load the srcnn model with weights\n",
    "    srcnn_model = predict_model()\n",
    "    srcnn_model.load_weights('srcnn.h5')\n",
    "    \n",
    "    # load the degraded and reference images\n",
    "    #_, hrfile = os.path.split(HR_PATH)\n",
    "    #_, lrfile = os.path.split(LR_PATH)\n",
    "    #degraded = cv2.imread(image_path)\n",
    "    #ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # preprocess the image with modcrop\n",
    "    hr_img = cv2.imread(HR_PATH)\n",
    "    shape = hr_img.shape\n",
    "\n",
    "    img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # two resize operation to produce training data and labels\n",
    "    lr_img = cv2.imread(LR_PATH)\n",
    "    lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "    lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2YCrCb)\n",
    "    lr_img = lr_img[:, :, 0]\n",
    "    \n",
    "    img[:, :, 0] = lr_img\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    Y = numpy.zeros((1, shape[0], shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = lr_img.astype(float) / 255.\n",
    "    \n",
    "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0\n",
    "    pre = pre.astype(numpy.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)    \n",
    "    score = psnr(hr_img,img)\n",
    "    \n",
    "    return score, hr_img, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Janice/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", input_shape=(None, Non..., kernel_size=(9, 9), filters=128, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
      "  \"\"\"\n",
      "/Users/Janice/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"relu\", kernel_size=(3, 3), filters=64, padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
      "  import sys\n",
      "/Users/Janice/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(activation=\"linear\", kernel_size=(5, 5), filters=1, padding=\"valid\", kernel_initializer=\"glorot_uniform\", use_bias=True)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving img_1327.jpg\n",
      "Saving img_1326.jpg\n",
      "Saving img_0326.jpg\n",
      "Saving img_0327.jpg\n",
      "Saving img_0127.jpg\n",
      "Saving img_0126.jpg\n"
     ]
    }
   ],
   "source": [
    "f = [x for x in os.listdir('LR/') if x != '.DS_Store' ]\n",
    "for file in f:\n",
    "    \n",
    "    # perform super-resolution\n",
    "    score, hr_img, sr_img = predict(LR_PATH='LR/{}'.format(file), HR_PATH='HR/{}'.format(file))\n",
    "    \n",
    "    # display images as subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    axs[0].imshow(cv2.cvtColor(hr_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Original')\n",
    "    axs[1].imshow(cv2.cvtColor(sr_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title('Super Resolution')\n",
    "    axs[1].set(xlabel = 'PSNR: {}\\n'.format(score))\n",
    "\n",
    "\n",
    "    # remove the x and y ticks\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "      \n",
    "    print('Saving {}'.format(file))\n",
    "    fig.savefig('/Users/Janice/Documents/Jupyter/output/{}.png'.format(os.path.splitext(file)[0])) \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
